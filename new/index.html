<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gowthami Somepalli</title>
    <link rel="stylesheet" href="style.css">
    <link rel="icon" href="../favicons/favicon.ico">
</head>
<body>
    <div class="container">
        <nav>
            <a href="index.html" class="active">home</a>
            <a href="blog.html">blog</a>
            <a href="../files/Gowthami_CV.pdf">cv</a>
        </nav>

        <header>
            <div class="header-content">
                <div class="intro">
                    <h1>Gowthami Somepalli</h1>
                    <p class="tagline">PhD @ UMD · Computer Vision · Diffusion Models</p>

                    <div class="links">
                        <a href="https://github.com/somepago">github</a>
                        <a href="https://scholar.google.com/citations?user=T2ezBDsAAAAJ">scholar</a>
                        <a href="https://twitter.com/gowthami_s">twitter</a>
                        <a href="https://www.linkedin.com/in/gowthamis/">linkedin</a>
                    </div>
                </div>
                <div class="portrait-container">
                    <img src="../files/g_dp_crop.jpg" alt="Gowthami Somepalli" class="portrait">
                </div>
            </div>
        </header>

        <main>
            <section class="about">
                <p>
                    I study how machines see and remember. As a PhD student advised by
                    <a href="https://www.cs.umd.edu/~tomg/">Tom Goldstein</a>, I've spent years
                    investigating <em>memorization in diffusion models</em>—earning me the nickname
                    "that memorization girl." <a href="https://www.youtube.com/watch?v=GbfgH3kHUbc">[video]</a>
                </p>
                <p>
                    Recently, I've been working on video understanding—creating
                    <a href="https://ruchitrawal.github.io/cinepile/">CinePile</a>, a long-video QA benchmark,
                    and exploring contextual captioning in Video-LLMs.
                </p>
                <p>
                    Before the PhD: 8 years in industry, a bachelor's from IIT Madras,
                    and a startup where I built ML tools for fashion.
                </p>
                <p class="contact">
                    Open to collaborations. <span class="email">sgowthami [at] umd.edu</span>
                </p>
            </section>

            <section class="visual-work">
                <h2>// selected visuals</h2>
                <div class="visual-grid">
                    <figure>
                        <img src="../projects/csd.png" alt="Style similarity in diffusion models">
                        <figcaption>Measuring style similarity in diffusion models <span class="venue">ECCV'24</span></figcaption>
                    </figure>
                    <figure>
                        <img src="../projects/repl_diff.png" alt="Diffusion replication study">
                        <figcaption>When AI copies: training data replication <span class="venue">CVPR'23</span></figcaption>
                    </figure>
                    <figure>
                        <img src="../projects/db.png" alt="Decision boundary visualization">
                        <figcaption>Visualizing neural network decision boundaries <span class="venue">CVPR'22 Oral</span></figcaption>
                    </figure>
                    <figure>
                        <img src="../projects/cinepile.png" alt="CinePile benchmark">
                        <figcaption>CinePile: long video understanding <span class="venue">Best Paper @ Synth4CV</span></figcaption>
                    </figure>
                </div>
            </section>

            <section class="papers">
                <h2>// papers</h2>

                <article class="paper">
                    <span class="year">2024</span>
                    <div class="paper-content">
                        <a href="../files/CALVIN_Neurips.pdf">Calvin: Improved Contextual Video Captioning via Instruction Tuning</a>
                        <span class="venue">NeurIPS</span>
                    </div>
                </article>

                <article class="paper">
                    <span class="year">2024</span>
                    <div class="paper-content">
                        <a href="https://ruchitrawal.github.io/cinepile/">CinePile: A Long Video Question Answering Dataset and Benchmark</a>
                        <span class="venue">CVPR Workshop · Best Paper</span>
                    </div>
                </article>

                <article class="paper">
                    <span class="year">2024</span>
                    <div class="paper-content">
                        <a href="https://arxiv.org/abs/2404.01292">Measuring Style Similarity in Diffusion Models</a>
                        <span class="venue">ECCV</span>
                    </div>
                </article>

                <article class="paper">
                    <span class="year">2023</span>
                    <div class="paper-content">
                        <a href="https://arxiv.org/abs/2305.20086">Understanding and Mitigating Copying in Diffusion Models</a>
                        <span class="venue">NeurIPS</span>
                    </div>
                </article>

                <article class="paper">
                    <span class="year">2023</span>
                    <div class="paper-content">
                        <a href="https://arxiv.org/abs/2212.03860">Diffusion Art or Digital Forgery? Investigating Data Replication</a>
                        <span class="venue">CVPR</span>
                    </div>
                </article>

                <article class="paper">
                    <span class="year">2022</span>
                    <div class="paper-content">
                        <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Somepalli_Can_Neural_Nets_Learn_the_Same_Model_Twice_Investigating_Reproducibility_CVPR_2022_paper.pdf">Can Neural Nets Learn the Same Model Twice?</a>
                        <span class="venue">CVPR · Oral</span>
                    </div>
                </article>

                <article class="paper">
                    <span class="year">2022</span>
                    <div class="paper-content">
                        <a href="https://openreview.net/pdf?id=FiyUTAy4sB8">SAINT: Neural Networks for Tabular Data</a>
                        <span class="venue">NeurIPS TRLW</span>
                    </div>
                </article>

                <article class="paper">
                    <span class="year">2021</span>
                    <div class="paper-content">
                        <a href="https://proceedings.neurips.cc/paper/2021/hash/dac32839a9f0baae954b41abee610cc0-Abstract.html">PatchGame: Learning to Signal Mid-level Patches</a>
                        <span class="venue">NeurIPS</span>
                    </div>
                </article>

                <p class="more-papers"><a href="https://scholar.google.com/citations?user=T2ezBDsAAAAJ">all papers →</a></p>
            </section>

            <section class="news">
                <h2>// news</h2>
                <ul>
                    <li><span class="date">Jul '24</span> 2 papers at NeurIPS'24</li>
                    <li><span class="date">Jul '24</span> CSD accepted to ECCV'24</li>
                    <li><span class="date">Jun '24</span> Best paper award at Synth4CV, CVPR</li>
                    <li><span class="date">Mar '24</span> Ann-Wylie Fellowship</li>
                    <li><span class="date">Dec '23</span> Talk at NeurIPS Diffusion Workshop</li>
                    <li><span class="date">Dec '22</span> Work covered in <a href="https://techcrunch.com/2022/12/13/image-generating-ai-can-copy-and-paste-from-training-data-raising-ip-concerns/">TechCrunch</a></li>
                </ul>
            </section>
        </main>

        <footer>
            <p>© 2025 · built with plain html</p>
        </footer>
    </div>

    <script>
        // Typewriter cursor blink effect for tagline
        const tagline = document.querySelector('.tagline');
        if (tagline) {
            tagline.innerHTML += '<span class="cursor">|</span>';
        }
    </script>
</body>
</html>
