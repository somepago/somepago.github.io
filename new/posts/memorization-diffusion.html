<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Why Diffusion Models Memorize · Gowthami Somepalli</title>
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="post.css">
    <link rel="icon" href="../../favicons/favicon.ico">
</head>
<body>
    <div class="container">
        <nav>
            <a href="../index.html">home</a>
            <a href="../blog.html">blog</a>
            <a href="../../files/Gowthami_CV.pdf">cv</a>
        </nav>

        <article class="post">
            <header class="post-header">
                <a href="../blog.html" class="back-link">← back to blog</a>
                <h1>Why Diffusion Models Memorize: A Deep Dive</h1>
                <div class="post-meta">
                    <time>January 2025</time>
                    <span class="reading-time">~8 min read</span>
                </div>
                <div class="post-tags">
                    <span class="tag">diffusion</span>
                    <span class="tag">my paper</span>
                    <span class="tag">memorization</span>
                </div>
            </header>

            <div class="post-content">
                <p class="lead">
                    After publishing three papers on memorization in diffusion models, I wanted to write
                    a unified explainer of what we've learned. This post summarizes our findings and
                    provides practical takeaways.
                </p>

                <h2>The Discovery</h2>

                <p>
                    In late 2022, we made a surprising discovery: Stable Diffusion—trained on billions
                    of images—could sometimes generate near-exact copies of its training data. This
                    wasn't supposed to happen. The conventional wisdom was that with enough data
                    diversity, neural networks would learn general patterns, not memorize specific examples.
                </p>

                <figure>
                    <img src="../../projects/repl_diff.png" alt="Examples of replicated images">
                    <figcaption>
                        Examples of training images (left) and their near-copies generated by
                        Stable Diffusion (right). From our CVPR 2023 paper.
                    </figcaption>
                </figure>

                <h2>Why Does This Happen?</h2>

                <p>
                    Through extensive experiments, we identified several key factors:
                </p>

                <h3>1. Text Conditioning Matters Most</h3>

                <p>
                    The captions associated with images play a crucial role. When a unique or
                    highly specific caption is repeatedly paired with the same image, the model
                    learns to associate that text with that exact visual content.
                </p>

                <pre><code>// Highly specific caption = memorization risk
"A photo of John Doe at the 2019 Tech Conference,
wearing a blue shirt, standing next to the main stage"

// Generic caption = lower risk
"A person at a conference"</code></pre>

                <h3>2. Duplication in Training Data</h3>

                <p>
                    Images that appear multiple times in the training set are more likely to be
                    memorized. This seems obvious, but the scale of duplication in web-scraped
                    datasets like LAION is often underestimated.
                </p>

                <h3>3. Model Capacity vs. Data Size</h3>

                <p>
                    Larger models with more parameters can memorize more. But interestingly,
                    the relationship isn't linear—there's a complex interplay between model
                    size, training duration, and dataset size.
                </p>

                <h2>Mitigation Strategies</h2>

                <p>
                    In our NeurIPS 2023 follow-up, we proposed several approaches:
                </p>

                <ul>
                    <li><strong>Multiple captions per image:</strong> Training with diverse captions
                    for the same image reduces the text-image binding that leads to memorization.</li>
                    <li><strong>Deduplication:</strong> Removing or reducing duplicate images in
                    the training set.</li>
                    <li><strong>Early stopping:</strong> Training for fewer steps can reduce
                    memorization, though it may affect overall quality.</li>
                </ul>

                <h2>Implications for Practitioners</h2>

                <p>
                    If you're training or fine-tuning diffusion models:
                </p>

                <ol>
                    <li>Audit your training data for duplicates</li>
                    <li>Use caption augmentation during training</li>
                    <li>Test for memorization using our DCR metric</li>
                    <li>Consider the legal implications of potential replication</li>
                </ol>

                <h2>Related Papers</h2>

                <ul class="paper-links">
                    <li>
                        <a href="https://arxiv.org/abs/2212.03860">Diffusion Art or Digital Forgery?</a>
                        — CVPR 2023
                    </li>
                    <li>
                        <a href="https://arxiv.org/abs/2305.20086">Understanding and Mitigating Copying</a>
                        — NeurIPS 2023
                    </li>
                    <li>
                        <a href="https://arxiv.org/abs/2404.01292">Measuring Style Similarity</a>
                        — ECCV 2024
                    </li>
                </ul>

                <div class="post-footer">
                    <p>
                        Questions or thoughts? Reach out on
                        <a href="https://twitter.com/gowthami_s">Twitter</a> or email me.
                    </p>
                </div>
            </div>
        </article>

        <footer>
            <p>© 2025 · built with plain html</p>
        </footer>
    </div>
</body>
</html>
